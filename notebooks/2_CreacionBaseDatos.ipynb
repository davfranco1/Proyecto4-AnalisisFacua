{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook #2: Creación de Base de Datos SQL\n",
    "\n",
    "En este segundo notebook crearemos nuestra base de datos.\n",
    "\n",
    "- El primer paso será importar las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para tratamiento de datos\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) # Parámetro que modifica la visualización de los DFs\n",
    "import numpy as np\n",
    "\n",
    "# Librería para el acceso a variables y funciones\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src import soporte_funciones as sf #Archivo .py donde encontraremos todas nuestras funciones.\n",
    "from src import soporte_variables as sv\n",
    "\n",
    "# Librería para trabajar con bases de datos SQL\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError, errorcodes, errors\n",
    "\n",
    "# Librería para ignorar avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Ignora TODOS los avisos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ahora importaremos los CSVs creados en el notebook anterior, y crearemos listas de tuplas, que es el formato necesario para la carga a la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = [\"supermercados\", \"productos\", \"categorias\", \"historico\"]\n",
    "df_dict = {csv: pd.DataFrame() for csv in csvs}\n",
    "dicc_tuplas = {}\n",
    "\n",
    "# Carga de archivos CSV\n",
    "for csv in csvs:\n",
    "    directorio = f\"../datos/df_{csv}.csv\"\n",
    "    df_dict[csv] = pd.read_csv(directorio, index_col=0)\n",
    "\n",
    "# Conversión a tuplas (tipo de dato aceptado para cargar datos a una base de datos SQL)\n",
    "for csv in csvs:\n",
    "    dicc_tuplas[csv] = [tuple(fila) for fila in df_dict[csv].values]\n",
    "\n",
    "# Asignación a variables\n",
    "lista_tuplas_supermercados = dicc_tuplas[\"supermercados\"]\n",
    "lista_tuplas_productos = dicc_tuplas[\"productos\"]\n",
    "lista_tuplas_categorias = dicc_tuplas[\"categorias\"]\n",
    "lista_tuplas_historico = dicc_tuplas[\"historico\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los datos se insertarán en las tablas que crearemos a continuación, con ayuda de las queries de creación definidas en `src/soporte_variables.py`.\n",
    "\n",
    "- Para crear esas tablas, hemos decidido que nuestra base de datos se estructurará de la manera en que vemos en el siguiente esquema entidad relación, que muestra la información que contiene cada tabla y cómo se relaciona entre sí. En el README del proyecto se explica su diseño.\n",
    "\n",
    "<img src=\"../images/Diagrama_ER.png\" width=\"300\">\n",
    "\n",
    "\n",
    "- En este caso utilizaremos dos funciones:\n",
    "\n",
    "    - `sf.dbeaver_conexion()`: recibe como parámetro el nombre de la base de datos de DBeaver y crea la conexión entre el notebook y la base de datos.\n",
    "    - `sf.dbeaver_commit()`: recibe como parámetros la conexión a DBeaver y la query de creación, realizando el commit hacia la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit realizado\n"
     ]
    }
   ],
   "source": [
    "sf.dbeaver_commit(sf.dbeaver_conexion(\"Facua\"),sv.query_creacion_supermercados)\n",
    "sf.dbeaver_commit(sf.dbeaver_conexion(\"Facua\"),sv.query_creacion_productos)\n",
    "sf.dbeaver_commit(sf.dbeaver_conexion(\"Facua\"),sv.query_creacion_categorias)\n",
    "sf.dbeaver_commit(sf.dbeaver_conexion(\"Facua\"),sv.query_creacion_historico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con las tablas preparadas, continuamos con la inserción de los mismos.\n",
    "- Usaremos la función `sf.dbeaver_commitmany()`, que recibe como argumentos:\n",
    "    - la conexión a DBeaver (usando la función de conexión),\n",
    "    - las queries de inserción que hemos definido en `src/soporte_variables.py` y,\n",
    "    - los datos que deseamos insertar, en este caso, las listas de tuplas preparadas anteriormente.\n",
    "- Esta función envía múltiples datos desde el notebook hacia la base de datos DBeaver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit realizado\n"
     ]
    }
   ],
   "source": [
    "sf.dbeaver_commitmany(sf.dbeaver_conexion(\"Facua\"),sv.query_insercion_supermercados,lista_tuplas_supermercados)\n",
    "sf.dbeaver_commitmany(sf.dbeaver_conexion(\"Facua\"),sv.query_insercion_productos,lista_tuplas_productos)\n",
    "sf.dbeaver_commitmany(sf.dbeaver_conexion(\"Facua\"),sv.query_insercion_categorias,lista_tuplas_categorias)\n",
    "sf.dbeaver_commitmany(sf.dbeaver_conexion(\"Facua\"),sv.query_insercion_historico,lista_tuplas_historico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con los datos insertados, podemos empezar a trabajar sobre nuestra base de datos. Continuamos con las consultas a la base de datos, la visualización y el análisis en el Notebook #3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
